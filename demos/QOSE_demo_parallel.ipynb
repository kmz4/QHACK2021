{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "helpful-income",
   "metadata": {},
   "source": [
    "### QOSE: MPI and SV1 parallelization on AWS \n",
    "\n",
    "In order to make our algorithm scalable and utilize the complete software stack as efficiently as possible, we parallelize the concurrent evaluation of circuits in our search tree as well as allowing for fast evaluation of quantum gradients using the SV1 Braket simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "actual-customs",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-uruguay",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Here, we briefly demo the parallel version of QOSE. This code was run succesfully on a ml.m5.24xlarge AWS instance with 96 CPUs, allow for massive parallel evaluation of all proposed circuit architectures in the leaves of the search tree. We used the MPI4Py Message Passing Interface (MPI) to dynamically spawn indivual processes for all leaves in the tree. Since training circuits takes up most of the time, the overhead due to messages being send or blocking due to processes not finishing at the same time is neglible compared to the speed up we can obtain with this approach. Although not fully stable, this version of the code was able to run about 3300 variational circuits for 20 steps (a depth 10 tree with prune rate 0.15) in about three. In additionan, each individual circuit was trained for 3 possible batch sizes and 3 possible learning rates, bringing the total of trained architectures to about $9\\times 3300 \\approx 30000$.\n",
    "\n",
    "In order to run this code, we expect the `qose` package to be installed succesfully with \n",
    "```\n",
    "python setup.py install\n",
    "```\n",
    "Let's get started. Open up `driver_code_par.py`. In this file, we first import all the relevant packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "medical-memphis",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from qose.subarchitecture_tree_search_par import run_tree_architecture_search\n",
    "import pennylane as qml\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-factor",
   "metadata": {},
   "source": [
    "Next, we first create a unique directory to store the data of our tree search algorithm. This will allow us to inspect the tree later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wrong-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EXPERIMENT_NAME = 'demo'\n",
    "\n",
    "# Create a directory to store the data\n",
    "if not os.path.exists('data'):\n",
    "    os.mkdir('data/')\n",
    "\n",
    "data_path = f'data/{EXPERIMENT_NAME}'\n",
    "if not os.path.exists(data_path):\n",
    "    os.mkdir(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-viking",
   "metadata": {},
   "source": [
    "To configure the tree search, we create a configuration file that will be passed to the algorithm. Please refer to the docs of `qose.subarchitecture_tree_search_par` for more detailed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "psychological-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'nqubits': 3,  # number of qubits in the circuit\n",
    "          'embedding': 'E1', # what embedding to use\n",
    "          'min_tree_depth': 4,  # minimum depth before we start pruning\n",
    "          'max_tree_depth': 10,  # maximum circuit depth\n",
    "          'prune_rate': 0.15, # rate with which to prune leaves\n",
    "          'prune_step': 3, # prune only if we have reached min_tree_depth and if (depth % prune_step) == 0\n",
    "          'plot_trees': False, # whether or not to plot trees during algorithm (graphviz required!)\n",
    "          'data_set': 'moons',  # the data set\n",
    "          'nsteps': 20, # number of steps for variational training\n",
    "          'optim': qml.AdamOptimizer, # pennylane optimizer\n",
    "          'batch_sizes': [8, 16, 32, 64], # batch sizes to check for each circuit we construct.\n",
    "          'n_samples': 1500, # number of samples of the data\n",
    "          'learning_rates': [0.001, 0.005, 0.01], # learning rates to check for each circuit we construct.\n",
    "          'save_frequency': 1, # how often save the tree to pickle, 1 means always, 0 never\n",
    "          'save_path': data_path, # where to save the data\n",
    "          'nprocesses': 5, # number of MPI processes spawned, controls the degree of parallelization.\n",
    "          'save_timing': False, # store the time how long each circuit tranining takes\n",
    "          'circuit_type': 'schuld', # specify the list of possible layers (see docs for more info)\n",
    "          'Tmax': [100, 100, 100], # parameters for w-cost function\n",
    "          'inf_time': 'numcnots', # how to determine circuit time, can be with CNOT number of clock time.\n",
    "          'fill': 'redundant',  # embedding parameter \n",
    "          'rate_type': 'accuracy',  # how to evaluate error rate for w-cost\n",
    "          'readout_layer': 'one_hot',  # how to do classiciation.\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-finnish",
   "metadata": {},
   "source": [
    "Then, we save the config so we can remember the details of our experiment,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spiritual-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + '/config.pickle', 'wb') as f:\n",
    "    pickle.dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-commonwealth",
   "metadata": {},
   "source": [
    "Finally, we call the function we imported earlier, passing the config and a string specifying if we want to calculate gradients locally, or remotely using the AWS braket SV1 simulator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-breathing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth = 1\n",
      "current graph:  [('ROOT', {'W': 0.0}), ('E1', {'W': 1.0})]\n",
      "Depth = 2\n",
      "Current best architecture:  E1\n",
      "max W: 1.0\n",
      "Sending chunks: ['E1:ZZ', 'E1:X', 'E1:Y', 'E1:Z']\n"
     ]
    }
   ],
   "source": [
    "run_tree_architecture_search(config, 'local') # if set to 'remote', make sure that S3 buckets and credentials are configured correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-occurrence",
   "metadata": {},
   "source": [
    "Since we are using MPI4py, we need launch with a special script, otherwise it will do nothing:\n",
    "Open a terminal in the location of the `demo_qose_par.py` file and type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mpiexec -n 1 python drive_code_par.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-acrylic",
   "metadata": {},
   "source": [
    "If succesful, the master process the controls the logic of the tree should start sending circuit architectures to dynamically spawned subprocesses, \n",
    "and print something like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-defeat",
   "metadata": {},
   "source": [
    "```bash\n",
    "Depth = 1\n",
    "current graph:  [('ROOT', {'W': 0.0}), ('E1', {'W': 1.0})]\n",
    "Depth = 2\n",
    "Current best architecture:  E1\n",
    "max W: 1.0\n",
    "Sending chunks: ['E1:ZZ', 'E1:X', 'E1:Y', 'E1:Z']\n",
    "CPU 0 doing E1:ZZ\n",
    "CPU 2 doing E1:Y\n",
    "CPU 1 doing E1:X\n",
    "CPU 3 doing E1:Z\n",
    "Depth = 3\n",
    "Current best architecture:  E1:Y\n",
    "max W: 1.8187496589844392\n",
    "Sending chunks: ['E1:ZZ:X', 'E1:ZZ:Y', 'E1:ZZ:Z', 'E1:X:ZZ', 'E1:X:Y', 'E1:X:Z', 'E1:Y:ZZ', 'E1:Y:X', 'E1:Y:Z', 'E1:Z:ZZ', 'E1:Z:X', 'E1:Z:Y']\n",
    "CPU 0 doing E1:ZZ:X\n",
    "CPU 1 doing E1:ZZ:Y\n",
    "CPU 3 doing E1:X:ZZ\n",
    "CPU 4 doing E1:X:Y\n",
    "CPU 8 doing E1:Y:Z\n",
    "CPU 9 doing E1:Z:ZZ\n",
    "CPU 11 doing E1:Z:Y\n",
    "CPU 7 doing E1:Y:X\n",
    "CPU 2 doing E1:ZZ:Z\n",
    "CPU 6 doing E1:Y:ZZ\n",
    "CPU 10 doing E1:Z:X\n",
    "CPU 5 doing E1:X:Z\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-filing",
   "metadata": {},
   "source": [
    "Indicating that the parallel execution is working as intented.We can take a deeper look at the logic being implemented in the parallel version of run_tree_architecture_search. Once a set of possible architectures has been established at depth $d$ of the tree, we feed it to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "finnish-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_all_leaves_parallel(G, leaves_at_depth_d, d, config):\n",
    "    \"\"\"\n",
    "    Function that handles training leaves in parallel through MPI\n",
    "    \n",
    "    Args:\n",
    "      G: nx.Digraph object containing the tree\n",
    "      leaves_at_depth_d: dictionary with key `depth` and values a list of possible architectures in the form of strings.\n",
    "      d: current depth\n",
    "      config: configuration file\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    # loop over the leaves in chunks, where chunksize is dictated by the maximum number of processes we allow for.\n",
    "    for leaves_chunked in chunks(leaves_at_depth_d[d], config['nprocesses']):\n",
    "        print(f'Sending chunks: {leaves_chunked}')\n",
    "        # dynamically create a process that executes mpi_evaluate_w.py\n",
    "        comm = MPI.COMM_SELF.Spawn(sys.executable,\n",
    "                                   args=['mpi_evaluate_w.py'],\n",
    "                                   maxprocs=len(leaves_chunked))\n",
    "        # broadcast the config and all architecture strings to all the subprocesses.\n",
    "        comm.bcast([leaves_chunked, config['save_path'] + '/MPI_data.pickle'], root=MPI.ROOT)\n",
    "        w_cost_sent = None\n",
    "        # BLOCKING: retrieve all w_costs from all spawned children.\n",
    "        w_cost_received = comm.gather(w_cost_sent, root=MPI.ROOT)\n",
    "        comm.Disconnect()\n",
    "        # Assign the obtained costs to the leaves.\n",
    "        for l, leaf in enumerate(leaves_chunked):\n",
    "            attrs = {\"W\": w_cost_received[l]}\n",
    "            for kdx in attrs.keys():\n",
    "                G.nodes[leaf][kdx] = attrs[kdx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-exploration",
   "metadata": {},
   "source": [
    "So we dynamically create multiple processes that all execute `mpi_evaluate_w.py`, broadcasting the possible architectures to all subprocesses. The subprocesses decide which one to execute based on their rank. For instance, say we broadcast the architectures:\n",
    "```\n",
    "['E1:ZZ:X', 'E1:ZZ:Y', 'E1:ZZ:Z', 'E1:X:ZZ', 'E1:X:Y']\n",
    "```\n",
    "to 5 subprocesses. In `mpi_evaluate_w.py` we then select a single architecture based on the child process' rank:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-ratio",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "```python\n",
    "from mpi4py import MPI\n",
    "import numpy\n",
    "from qose.train_utils import evaluate_w\n",
    "from qose.circuit_utils import construct_circuit_from_leaf\n",
    "import pickle\n",
    "\n",
    "comm = MPI.Comm.Get_parent()\n",
    "size = comm.Get_size() # size will equal the maxprocs that we used in Spawn\n",
    "rank = comm.Get_rank() # rank is an integer from 0,..,size-1, unique for each child process\n",
    "\n",
    "architectures = None\n",
    "save_path = None\n",
    "# obtain all the possible architectures with MPI broadcasting\n",
    "data = comm.bcast(numpy.zeros(size), root=0)\n",
    "# select a leaf to run based on the child process' rank\n",
    "leaf = data[0][rank]\n",
    "save_path = data[1]\n",
    "print(f'CPU {rank} doing {leaf}')\n",
    "# hacky way to ensure that we don't have to transfer all the data that remains contant over MPI\n",
    "with open(save_path, 'rb') as pdata:\n",
    "    pickled_data_for_MPI = pickle.load(pdata)\n",
    "NQUBITS, NCLASSES, dev, config, X_train, y_train_ohe = pickled_data_for_MPI\n",
    "\n",
    "# construct the unique circuit\n",
    "circuit, pshape, numcnots = construct_circuit_from_leaf(leaf, NQUBITS, NCLASSES, dev, config)\n",
    "config['numcnots'] = numcnots\n",
    "# run the training\n",
    "w_cost, _ = evaluate_w(circuit, pshape, X_train, y_train_ohe, **config)\n",
    "# send back the cost to the master MPI comm.\n",
    "comm.gather(w_cost, root=0)\n",
    "\n",
    "comm.Disconnect()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-rental",
   "metadata": {},
   "source": [
    "Hence if we are child with `rank=0`, we will evaluate circuit architecture `'E1:ZZ:X'`.\n",
    "\n",
    "And that's all she wrote. This implementation is far from perfect, but does showcase the relative ease with which embarrasingly parallel computations in QML can be scaled efficiently on large AWS clusters! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-nurse",
   "metadata": {},
   "source": [
    "![Succesful parallel execution on a ml.m5.24xlarge instance](aws_qose.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-drain",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
