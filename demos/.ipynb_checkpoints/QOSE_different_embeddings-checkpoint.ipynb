{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "younger-dakota",
   "metadata": {},
   "source": [
    "In this demo, we try to see how using different embeddings might result in different optimized architectures whilst keeping other hyper parameters and data the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-butterfly",
   "metadata": {},
   "source": [
    "We have six built-in embeddings available. They are represented by the string 'E1' to 'E6' as:\n",
    "    \n",
    "    'E1': angle embedding with Rot_Y\n",
    "    'E2': amplitude embedding\n",
    "    'E3': qaoa variational hamiltonian ansatz inspired embedding\n",
    "    'E4': XXZ variational hamiltonian ansatz inspired embedding\n",
    "    'E5': the most expressive circuit from aspuru guzik group 2019 paper\n",
    "    'E6': random embedding with randomly selected rot gates and CNOTs\n",
    "        \n",
    "As with other system specifications, you can set the embedding you want to use in the system configuration dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cheap-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we import the essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "closed-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adjacent-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qose.subarchitecture_tree_search import run_tree_architecture_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assigned-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create a unique name for your experiment\n",
    "    EXPERIMENT_NAME = 'VariousEmbeddings'\n",
    "\n",
    "    # Create a directory to store the data\n",
    "    if not os.path.exists('data'):\n",
    "        os.mkdir('data/')\n",
    "\n",
    "    data_path = f'data/{EXPERIMENT_NAME}'\n",
    "    if not os.path.exists(data_path):\n",
    "        os.mkdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "expanded-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'nqubits': 2,  # number of qubits in the circuit\n",
    "          'embedding': 'E1', # what embedding to use\n",
    "          'min_tree_depth': 4,  # minimum depth before we start pruning\n",
    "          'max_tree_depth': 6,  # maximum circuit depth\n",
    "          'prune_rate': 0.15, # rate with which to prune leaves\n",
    "          'prune_step': 3, # prune only if we have reached min_tree_depth and if (depth % prune_step) == 0\n",
    "          'plot_trees': False, # whether or not to plot trees during algorithm (graphviz required!)\n",
    "          'data_set': 'moons',  # the data set\n",
    "          'nsteps': 20, # number of steps for variational training\n",
    "          'optim': qml.AdamOptimizer, # pennylane optimizer\n",
    "          'batch_sizes': [8], # batch sizes to check for each circuit we construct.\n",
    "          'n_samples': 1500, # number of samples of the data\n",
    "          'learning_rates': [0.01], # learning rates to check for each circuit we construct.\n",
    "          'save_frequency': 1, # how often save the tree to pickle, 1 means always, 0 never\n",
    "          'save_path': data_path, # where to save the data\n",
    "          'nprocesses': 5, # number of MPI processes spawned, controls the degree of parallelization.\n",
    "          'save_timing': False, # store the time how long each circuit tranining takes\n",
    "          'circuit_type': 'schuld', # specify the list of possible layers (see docs for more info)\n",
    "          'Tmax': [100, 100, 100], # parameters for w-cost function\n",
    "          'inf_time': 'numcnots', # how to determine circuit time, can be with CNOT number of clock time.\n",
    "          'fill': 'redundant',  # embedding parameter \n",
    "          'rate_type': 'accuracy',  # how to evaluate error rate for w-cost\n",
    "          'readout_layer': 'one_hot',  # how to do classiciation.\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "least-marsh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########Embedding:  E1\n",
      "Depth = 1\n",
      "Depth = 2\n",
      "Current best architecture:  E1\n",
      "max W: 1.0\n",
      "weights: []\n",
      "Training leaf E1:ZZ\n",
      "Training leaf E1:X\n",
      "Training leaf E1:Y\n",
      "Training leaf E1:Z\n",
      "Depth = 3\n",
      "Current best architecture:  E1:X\n",
      "max W: 2.070422097798148\n",
      "weights: [[0.18432993]\n",
      " [0.11447192]]\n",
      "Training leaf E1:ZZ:X\n",
      "Training leaf E1:ZZ:Y\n",
      "Training leaf E1:ZZ:Z\n",
      "Training leaf E1:X:ZZ\n",
      "Training leaf E1:X:Y\n",
      "Training leaf E1:X:Z\n",
      "Training leaf E1:Y:ZZ\n",
      "Training leaf E1:Y:X\n",
      "Training leaf E1:Y:Z\n",
      "Training leaf E1:Z:ZZ\n",
      "Training leaf E1:Z:X\n",
      "Training leaf E1:Z:Y\n",
      "Depth = 4\n",
      "Prune Tree\n",
      "Current best architecture:  E1:Y:X\n",
      "max W: 2.2615379396450908\n",
      "weights: [[0.09355039 0.09516496]\n",
      " [0.1702017  0.17383168]]\n",
      "Grow Pruned Tree\n",
      "Depth = 5\n",
      "Grow Tree\n",
      "Current best architecture:  E1:X:Y:X\n",
      "max W: 2.449999387500153\n",
      "weights: [[0.14993716 0.17651175 0.14987826]\n",
      " [0.18447972 0.17387657 0.18443745]]\n",
      "architecture with max W:  E1:Y:Z:Y:X\n",
      "max W: 2.999999081632934\n",
      "weights:  [[ 0.12262601 -0.17781427  0.12071927  0.12554879]\n",
      " [ 0.16658778 -0.17519706  0.16533146  0.15749411]]\n",
      "*********Time taken for E1  embedding:  248.6836211681366\n",
      "##########Embedding:  E2\n",
      "Depth = 1\n",
      "Depth = 2\n",
      "Current best architecture:  E1\n",
      "max W: 1.0\n",
      "weights: []\n",
      "Training leaf E1:ZZ\n",
      "Training leaf E1:X\n",
      "Training leaf E1:Y\n",
      "Training leaf E1:Z\n",
      "Depth = 3\n",
      "Current best architecture:  E1:X\n",
      "max W: 1.884615022189419\n",
      "weights: [[0.09157365]\n",
      " [0.09526238]]\n",
      "Training leaf E1:ZZ:X\n",
      "Training leaf E1:ZZ:Y\n",
      "Training leaf E1:ZZ:Z\n",
      "Training leaf E1:X:ZZ\n",
      "Training leaf E1:X:Y\n",
      "Training leaf E1:X:Z\n",
      "Training leaf E1:Y:ZZ\n",
      "Training leaf E1:Y:X\n",
      "Training leaf E1:Y:Z\n",
      "Training leaf E1:Z:ZZ\n",
      "Training leaf E1:Z:X\n",
      "Training leaf E1:Z:Y\n",
      "Depth = 4\n",
      "Prune Tree\n",
      "Current best architecture:  E1:Y:X\n",
      "max W: 1.9599996080000786\n",
      "weights: [[0.09373709 0.08958432]\n",
      " [0.0979582  0.09923675]]\n",
      "Grow Pruned Tree\n",
      "Depth = 5\n",
      "Grow Tree\n",
      "Current best architecture:  E1:Y:Z:Y\n",
      "max W: 2.194029359545666\n",
      "weights: [[0.16396533 0.13877499 0.1645464 ]\n",
      " [0.12137825 0.15029323 0.12259305]]\n",
      "architecture with max W:  E1:X:Y:X:Y\n",
      "max W: 3.195651131852892\n",
      "weights:  [[0.08924254 0.08787964 0.08925228 0.08786294]\n",
      " [0.1704483  0.16700731 0.17055532 0.16688394]]\n",
      "*********Time taken for E2  embedding:  254.37891602516174\n",
      "##########Embedding:  E3\n",
      "Depth = 1\n",
      "Depth = 2\n",
      "Current best architecture:  E1\n",
      "max W: 1.0\n",
      "weights: []\n",
      "Training leaf E1:ZZ\n",
      "Training leaf E1:X\n",
      "Training leaf E1:Y\n",
      "Training leaf E1:Z\n",
      "Depth = 3\n",
      "Current best architecture:  E1:Y\n",
      "max W: 1.9090905371901554\n",
      "weights: [[0.11442767]\n",
      " [0.15075714]]\n",
      "Training leaf E1:ZZ:X\n",
      "Training leaf E1:ZZ:Y\n",
      "Training leaf E1:ZZ:Z\n",
      "Training leaf E1:X:ZZ\n",
      "Training leaf E1:X:Y\n",
      "Training leaf E1:X:Z\n",
      "Training leaf E1:Y:ZZ\n",
      "Training leaf E1:Y:X\n",
      "Training leaf E1:Y:Z\n",
      "Training leaf E1:Z:ZZ\n",
      "Training leaf E1:Z:X\n",
      "Training leaf E1:Z:Y\n",
      "Depth = 4\n",
      "Prune Tree\n",
      "Current best architecture:  E1:X:Y\n",
      "max W: 2.2615379396450908\n",
      "weights: [[0.09652728 0.0989998 ]\n",
      " [0.10791021 0.10864434]]\n",
      "Grow Pruned Tree\n",
      "Depth = 5\n",
      "Grow Tree\n",
      "Current best architecture:  E1:X:Y\n",
      "max W: 2.2615379396450908\n",
      "weights: [[0.09652728 0.0989998 ]\n",
      " [0.10791021 0.10864434]]\n",
      "architecture with max W:  E1:Y:Z:Y:X\n",
      "max W: 2.578946689750871\n",
      "weights:  [[ 0.11965595 -0.17279694  0.11784141  0.10679195]\n",
      " [ 0.11523072 -0.1703196   0.1132928   0.10495673]]\n",
      "*********Time taken for E3  embedding:  249.27114391326904\n",
      "##########Embedding:  E4\n",
      "Depth = 1\n",
      "Depth = 2\n",
      "Current best architecture:  E1\n",
      "max W: 1.0\n",
      "weights: []\n",
      "Training leaf E1:ZZ\n",
      "Training leaf E1:X\n",
      "Training leaf E1:Y\n",
      "Training leaf E1:Z\n",
      "Depth = 3\n",
      "Current best architecture:  E1:Y\n",
      "max W: 1.8374996554688148\n",
      "weights: [[0.1145235 ]\n",
      " [0.14422652]]\n",
      "Training leaf E1:ZZ:X\n",
      "Training leaf E1:ZZ:Y\n",
      "Training leaf E1:ZZ:Z\n",
      "Training leaf E1:X:ZZ\n",
      "Training leaf E1:X:Y\n",
      "Training leaf E1:X:Z\n",
      "Training leaf E1:Y:ZZ\n",
      "Training leaf E1:Y:X\n",
      "Training leaf E1:Y:Z\n",
      "Training leaf E1:Z:ZZ\n",
      "Training leaf E1:Z:X\n",
      "Training leaf E1:Z:Y\n",
      "Depth = 4\n",
      "Prune Tree\n",
      "Current best architecture:  E1:Y:Z\n",
      "max W: 2.070422097798148\n",
      "weights: [[ 1.26162656e-01 -3.03076786e-11]\n",
      " [ 1.23416085e-01  5.34367727e-12]]\n",
      "Grow Pruned Tree\n",
      "Depth = 5\n",
      "Grow Tree\n",
      "Current best architecture:  E1:X:Z:Y\n",
      "max W: 2.2968744616700483\n",
      "weights: [[0.09338381 0.16965684 0.09897233]\n",
      " [0.15483252 0.17802701 0.15397849]]\n",
      "architecture with max W:  E1:X:Y:X:Y\n",
      "max W: 3.4186034586267007\n",
      "weights:  [[0.11672922 0.14848596 0.11679911 0.14845654]\n",
      " [0.12470478 0.12416735 0.12479256 0.12407942]]\n",
      "*********Time taken for E4  embedding:  243.20222210884094\n",
      "##########Embedding:  E5\n",
      "Depth = 1\n",
      "Depth = 2\n",
      "Current best architecture:  E1\n",
      "max W: 1.0\n",
      "weights: []\n",
      "Training leaf E1:ZZ\n",
      "Training leaf E1:X\n",
      "Training leaf E1:Y\n",
      "Training leaf E1:Z\n",
      "Depth = 3\n",
      "Current best architecture:  E1:Y\n",
      "max W: 1.884615022189419\n",
      "weights: [[0.08820793]\n",
      " [0.1867541 ]]\n",
      "Training leaf E1:ZZ:X\n",
      "Training leaf E1:ZZ:Y\n",
      "Training leaf E1:ZZ:Z\n",
      "Training leaf E1:X:ZZ\n",
      "Training leaf E1:X:Y\n",
      "Training leaf E1:X:Z\n",
      "Training leaf E1:Y:ZZ\n",
      "Training leaf E1:Y:X\n",
      "Training leaf E1:Y:Z\n",
      "Training leaf E1:Z:ZZ\n",
      "Training leaf E1:Z:X\n",
      "Training leaf E1:Z:Y\n",
      "Depth = 4\n",
      "Prune Tree\n",
      "Current best architecture:  E1:X:Y\n",
      "max W: 1.9864860838203884\n",
      "weights: [[0.13097362 0.1153758 ]\n",
      " [0.09715514 0.09817381]]\n",
      "Grow Pruned Tree\n",
      "Depth = 5\n",
      "Grow Tree\n",
      "Current best architecture:  E1:Y:Z:X\n",
      "max W: 2.2968744616700483\n",
      "weights: [[ 0.09738793 -0.16497055  0.09164227]\n",
      " [ 0.12465344 -0.1793053   0.13488114]]\n",
      "architecture with max W:  E1:Y:X:Y:ZZ\n",
      "max W: 2.565817482049777\n",
      "weights:  [[ 9.01466501e-02  8.71899049e-02  9.01356227e-02 -2.72182440e-11]\n",
      " [ 1.14630961e-01  1.04703937e-01  1.14590789e-01 -3.38599558e-11]]\n",
      "*********Time taken for E5  embedding:  243.52616095542908\n",
      "##########Embedding:  E6\n",
      "Depth = 1\n",
      "Depth = 2\n",
      "Current best architecture:  E1\n",
      "max W: 1.0\n",
      "weights: []\n",
      "Training leaf E1:ZZ\n",
      "Training leaf E1:X\n",
      "Training leaf E1:Y\n",
      "Training leaf E1:Z\n",
      "Depth = 3\n",
      "Current best architecture:  E1:X\n",
      "max W: 1.9090905371901554\n",
      "weights: [[0.11563613]\n",
      " [0.10899268]]\n",
      "Training leaf E1:ZZ:X\n",
      "Training leaf E1:ZZ:Y\n",
      "Training leaf E1:ZZ:Z\n",
      "Training leaf E1:X:ZZ\n",
      "Training leaf E1:X:Y\n",
      "Training leaf E1:X:Z\n",
      "Training leaf E1:Y:ZZ\n",
      "Training leaf E1:Y:X\n",
      "Training leaf E1:Y:Z\n",
      "Training leaf E1:Z:ZZ\n",
      "Training leaf E1:Z:X\n",
      "Training leaf E1:Z:Y\n",
      "Depth = 4\n",
      "Prune Tree\n",
      "Current best architecture:  E1:X\n",
      "max W: 1.9090905371901554\n",
      "weights: [[0.11563613]\n",
      " [0.10899268]]\n",
      "Grow Pruned Tree\n",
      "Depth = 5\n",
      "Grow Tree\n",
      "Current best architecture:  E1:Y:X:Y\n",
      "max W: 2.578946689750871\n",
      "weights: [[0.09976753 0.0943659  0.0997504 ]\n",
      " [0.16963618 0.15972089 0.16960614]]\n",
      "architecture with max W:  E1:X:Z:X:Y\n",
      "max W: 2.6249992968751883\n",
      "weights:  [[ 0.11684631 -0.13083146  0.11991146  0.09594768]\n",
      " [ 0.19347524  0.15752423  0.19325648  0.18171114]]\n",
      "*********Time taken for E6  embedding:  252.51013588905334\n"
     ]
    }
   ],
   "source": [
    "possible_emb = ['E1', 'E2', 'E3','E4','E5','E6']\n",
    "for key in possible_emb:\n",
    "    config['embedding'] = key\n",
    "    print(\"##########Embedding: \", key)\n",
    "    t_0_local = time.time()\n",
    "    run_tree_architecture_search(config, \"local\")\n",
    "    t_1_local = time.time()\n",
    "    print(\"*********Time taken for\",key,\" embedding: \", t_1_local - t_0_local )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecological-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + '/config.pickle', 'wb') as f:\n",
    "        pickle.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-wrist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
