<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>qose.training_test API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>qose.training_test</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#! /usr/bin/python3

import sys
import pennylane as qml
import numpy as np
import sklearn as skl
import autograd.numpy as np
import itertools
import time

def train_circuit(circuit,n_params,n_cnots,X_train,Y_train,X_test,Y_test,optim,optimoptions,inference=&#39;wall_clock&#39;,rate_type=&#39;accuracy&#39;,**kwargs):
    &#34;&#34;&#34;Develop and train your very own variational quantum classifier.

    Use the provided training data to train your classifier. The code you write
    for this challenge should be completely contained within this function
    between the # QHACK # comment markers. The number of qubits, choice of
    variational ansatz, cost function, and optimization method are all to be
    developed by you in this function.

    Args:
        circuit (qml.QNode): A circuit that you want to train
        X_train (np.ndarray): An array of floats of size (M, n) to be used as training data.
        Y_train (np.ndarray): An array of size (M,) which are the categorical labels
            associated to the training data. The categories are labeled by -1, 0, and 1.
        X_test (np.ndarray): An array of floats of (B, n) to serve as testing data.
        kwargs: hyperparameters for the training (steps, batch_size, learning_rate)

    Returns:
        (p,i,e,w): The number of parameters, the inference time (time to evaluate the accuracy), error rate (accuracy on the test set)
    &#34;&#34;&#34;

    # Use this array to make a prediction for the labels of the data in X_test
    predictions = []

    # QHACK #

    from autograd.numpy import exp,tanh

    def hinge_loss(labels, predictions,type=&#39;L2&#39;):
        loss = 0
        for l, p in zip(labels, predictions):
            if type==&#39;L1&#39;:
                loss = loss + np.abs(l - p) # L1 loss
            elif type==&#39;L2&#39;:
                loss = loss + (l - p) ** 2 # L2 loss
        loss = loss/len(labels)
        return loss

    def accuracy(labels, predictions):

        loss = 0
        tol = 0.05
        #tol = 0.1
        for l, p in zip(labels, predictions):
            if abs(l - p) &lt; tol:
                loss = loss + 1
        loss = loss / len(labels)

        return loss

    def cost_fcn(params,circuit=None,ang_array=[], actual=[]):
        &#39;&#39;&#39;
        use MAE to start
        &#39;&#39;&#39;
        labels = {2:-1,1:1,0:0}
        n = len(ang_array[0])
        w = params[-n:]
        theta = params[:-n]
        predictions = [2.*(1.0/(1.0+exp(np.dot(-w,circuit(theta, angles=x)))))- 1. for x in ang_array]
        return hinge_loss(actual, predictions)

    var = np.hstack((np.zeros(n_params),5*np.random.random(X_train.shape[1])-2.5))
    steps = kwargs[&#39;s&#39;]
    batch_size = kwargs[&#39;batch_size&#39;]
    num_train = len(Y_train)
    validation_size = int(num_train//2)
    opt = optim(**optimoptions)
    start = time.time()
    for _ in range(steps):
        batch_index = np.random.randint(0, num_train, (batch_size,))
        X_train_batch = X_train[batch_index]
        Y_train_batch = Y_train[batch_index]
        var,cost = opt.step_and_cost(lambda v: cost_fcn(v, circuit,X_train_batch, Y_train_batch), var)
    end = time.time()
    cost_time = (end-start)

    w = var[-X_train.shape[1]:]
    theta = var[:-X_train.shape[1]]

    if rate_type ==&#39;accuracy&#39;:
        start = time.time() # add in timeit function from Wbranch
        predictions=[int(np.round(2.*(1.0/(1.0+exp(np.dot(-w,circuit(theta, angles=x)))))- 1.,0)) for x in X_test]
        end = time.time()
        if inference==&#39;wall_clock&#39;:
            inftime = (end-start)/len(X_test)
        err_rate = 1.0 - accuracy(predictions,Y_test)
    elif rate_type==&#39;batch_cost&#39;:
        err_rate = cost
        inftime = cost_time
    # QHACK #
    if inference==&#39;cnots&#39;:
        inftime=n_cnots
        
    W_ = np.abs((100.-len(var))/(100.))*np.abs((100.-inftime)/(100.))*(1./err_rate)
    return len(var),inftime,err_rate,W_


def classify_data(X_train,Y_train,X_test,Y_test,**kwargs):
    &#34;&#34;&#34;Develop and train your very own variational quantum classifier.

    Use the provided training data to train your classifier. The code you write
    for this challenge should be completely contained within this function
    between the # QHACK # comment markers. The number of qubits, choice of
    variational ansatz, cost function, and optimization method are all to be
    developed by you in this function.

    Args:
        X_train (np.ndarray): An array of floats of size (250, 3) to be used as training data.
        Y_train (np.ndarray): An array of size (250,) which are the categorical labels
            associated to the training data. The categories are labeled by -1, 0, and 1.
        X_test (np.ndarray): An array of floats of (50, 3) to serve as testing data.

    Returns:
        str: The predicted categories of X_test, converted from a list of ints to a
            comma-separated string.
    &#34;&#34;&#34;

    # Use this array to make a prediction for the labels of the data in X_test
    predictions = []

    # QHACK #

    from autograd.numpy import exp,tanh

    def statepreparation(a):
        qml.templates.embeddings.AngleEmbedding(a, wires=range(3), rotation=&#39;Y&#39;)

    def layer(W):
        qml.templates.layers.BasicEntanglerLayers(W, wires=range(3), rotation=qml.ops.RY)

    def hinge_loss(labels, predictions,type=&#39;L2&#39;):
        loss = 0
        for l, p in zip(labels, predictions):
            if type==&#39;L1&#39;:
                loss = loss + np.abs(l - p) # L1 loss
            elif type==&#39;L2&#39;:
                loss = loss + (l - p) ** 2 # L2 loss
        loss = loss/len(labels)
        return loss

    def accuracy(labels, predictions):

        loss = 0
        tol = 0.05
        #tol = 0.1
        for l, p in zip(labels, predictions):
            if abs(l - p) &lt; tol:
                loss = loss + 1
        loss = loss / len(labels)

        return loss

    def cost_fcn(params,circuit=None,ang_array=[], actual=[]):
        &#39;&#39;&#39;
        use MAE to start
        &#39;&#39;&#39;
        w = params[-3:]
        theta = params[:-3]
        predictions = [2.*(1.0/(1.0+exp(np.dot(-w,circuit(theta, angles=x)))))- 1. for x in ang_array]
        return hinge_loss(actual, predictions)

    dev = qml.device(&#34;default.qubit&#34;, wires=3)
    @qml.qnode(dev)
    def inside_circuit(params,angles=None):
        statepreparation(angles)
        W= np.reshape(params,(len(params)//3,3))
        layer(W)
        return qml.expval(qml.PauliZ(0)),qml.expval(qml.PauliZ(1)),qml.expval(qml.PauliZ(2))


    var = np.hstack((np.zeros(6),5*np.random.random(3)-2.5))
    steps = kwargs[&#39;s&#39;]
    batch_size = kwargs[&#39;batch_size&#39;]
    num_train = len(Y_train)
    validation_size = int(num_train//2)
    opt = qml.AdamOptimizer(kwargs[&#39;learning_rate&#39;])

    for _ in range(steps):
        batch_index = np.random.randint(0, num_train, (batch_size,))
        X_train_batch = X_train[batch_index]
        Y_train_batch = Y_train[batch_index]

        var,cost = opt.step_and_cost(lambda v: cost_fcn(v, inside_circuit,X_train_batch, Y_train_batch), var)

    # need timing values from computing predictions


    theta = var[:-3]
    w = var[-3:]
    start = time.time() # add in timeit function from Wbranch
    predictions=[int(np.round(2.*(1.0/(1.0+exp(np.dot(-w,inside_circuit(theta, angles=x)))))- 1.,0)) for x in X_test]
    end = time.time()
    inftime = end-start
    err_rate = 1.0 - accuracy(predictions,Y_test)
    # QHACK #
    W_ = len(var)*inftime*(1./err_rate)
    return len(var),inftime,err_rate,W_</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="qose.training_test.classify_data"><code class="name flex">
<span>def <span class="ident">classify_data</span></span>(<span>X_train, Y_train, X_test, Y_test, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Develop and train your very own variational quantum classifier.</p>
<p>Use the provided training data to train your classifier. The code you write
for this challenge should be completely contained within this function
between the # QHACK # comment markers. The number of qubits, choice of
variational ansatz, cost function, and optimization method are all to be
developed by you in this function.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X_train</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>An array of floats of size (250, 3) to be used as training data.</dd>
<dt><strong><code>Y_train</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>An array of size (250,) which are the categorical labels
associated to the training data. The categories are labeled by -1, 0, and 1.</dd>
<dt><strong><code>X_test</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>An array of floats of (50, 3) to serve as testing data.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>The predicted categories of X_test, converted from a list of ints to a
comma-separated string.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def classify_data(X_train,Y_train,X_test,Y_test,**kwargs):
    &#34;&#34;&#34;Develop and train your very own variational quantum classifier.

    Use the provided training data to train your classifier. The code you write
    for this challenge should be completely contained within this function
    between the # QHACK # comment markers. The number of qubits, choice of
    variational ansatz, cost function, and optimization method are all to be
    developed by you in this function.

    Args:
        X_train (np.ndarray): An array of floats of size (250, 3) to be used as training data.
        Y_train (np.ndarray): An array of size (250,) which are the categorical labels
            associated to the training data. The categories are labeled by -1, 0, and 1.
        X_test (np.ndarray): An array of floats of (50, 3) to serve as testing data.

    Returns:
        str: The predicted categories of X_test, converted from a list of ints to a
            comma-separated string.
    &#34;&#34;&#34;

    # Use this array to make a prediction for the labels of the data in X_test
    predictions = []

    # QHACK #

    from autograd.numpy import exp,tanh

    def statepreparation(a):
        qml.templates.embeddings.AngleEmbedding(a, wires=range(3), rotation=&#39;Y&#39;)

    def layer(W):
        qml.templates.layers.BasicEntanglerLayers(W, wires=range(3), rotation=qml.ops.RY)

    def hinge_loss(labels, predictions,type=&#39;L2&#39;):
        loss = 0
        for l, p in zip(labels, predictions):
            if type==&#39;L1&#39;:
                loss = loss + np.abs(l - p) # L1 loss
            elif type==&#39;L2&#39;:
                loss = loss + (l - p) ** 2 # L2 loss
        loss = loss/len(labels)
        return loss

    def accuracy(labels, predictions):

        loss = 0
        tol = 0.05
        #tol = 0.1
        for l, p in zip(labels, predictions):
            if abs(l - p) &lt; tol:
                loss = loss + 1
        loss = loss / len(labels)

        return loss

    def cost_fcn(params,circuit=None,ang_array=[], actual=[]):
        &#39;&#39;&#39;
        use MAE to start
        &#39;&#39;&#39;
        w = params[-3:]
        theta = params[:-3]
        predictions = [2.*(1.0/(1.0+exp(np.dot(-w,circuit(theta, angles=x)))))- 1. for x in ang_array]
        return hinge_loss(actual, predictions)

    dev = qml.device(&#34;default.qubit&#34;, wires=3)
    @qml.qnode(dev)
    def inside_circuit(params,angles=None):
        statepreparation(angles)
        W= np.reshape(params,(len(params)//3,3))
        layer(W)
        return qml.expval(qml.PauliZ(0)),qml.expval(qml.PauliZ(1)),qml.expval(qml.PauliZ(2))


    var = np.hstack((np.zeros(6),5*np.random.random(3)-2.5))
    steps = kwargs[&#39;s&#39;]
    batch_size = kwargs[&#39;batch_size&#39;]
    num_train = len(Y_train)
    validation_size = int(num_train//2)
    opt = qml.AdamOptimizer(kwargs[&#39;learning_rate&#39;])

    for _ in range(steps):
        batch_index = np.random.randint(0, num_train, (batch_size,))
        X_train_batch = X_train[batch_index]
        Y_train_batch = Y_train[batch_index]

        var,cost = opt.step_and_cost(lambda v: cost_fcn(v, inside_circuit,X_train_batch, Y_train_batch), var)

    # need timing values from computing predictions


    theta = var[:-3]
    w = var[-3:]
    start = time.time() # add in timeit function from Wbranch
    predictions=[int(np.round(2.*(1.0/(1.0+exp(np.dot(-w,inside_circuit(theta, angles=x)))))- 1.,0)) for x in X_test]
    end = time.time()
    inftime = end-start
    err_rate = 1.0 - accuracy(predictions,Y_test)
    # QHACK #
    W_ = len(var)*inftime*(1./err_rate)
    return len(var),inftime,err_rate,W_</code></pre>
</details>
</dd>
<dt id="qose.training_test.train_circuit"><code class="name flex">
<span>def <span class="ident">train_circuit</span></span>(<span>circuit, n_params, n_cnots, X_train, Y_train, X_test, Y_test, optim, optimoptions, inference='wall_clock', rate_type='accuracy', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Develop and train your very own variational quantum classifier.</p>
<p>Use the provided training data to train your classifier. The code you write
for this challenge should be completely contained within this function
between the # QHACK # comment markers. The number of qubits, choice of
variational ansatz, cost function, and optimization method are all to be
developed by you in this function.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>circuit</code></strong> :&ensp;<code>qml.QNode</code></dt>
<dd>A circuit that you want to train</dd>
<dt><strong><code>X_train</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>An array of floats of size (M, n) to be used as training data.</dd>
<dt><strong><code>Y_train</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>An array of size (M,) which are the categorical labels
associated to the training data. The categories are labeled by -1, 0, and 1.</dd>
<dt><strong><code>X_test</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>An array of floats of (B, n) to serve as testing data.</dd>
<dt><strong><code>kwargs</code></strong></dt>
<dd>hyperparameters for the training (steps, batch_size, learning_rate)</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>(p,i,e,w): The number of parameters, the inference time (time to evaluate the accuracy), error rate (accuracy on the test set)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train_circuit(circuit,n_params,n_cnots,X_train,Y_train,X_test,Y_test,optim,optimoptions,inference=&#39;wall_clock&#39;,rate_type=&#39;accuracy&#39;,**kwargs):
    &#34;&#34;&#34;Develop and train your very own variational quantum classifier.

    Use the provided training data to train your classifier. The code you write
    for this challenge should be completely contained within this function
    between the # QHACK # comment markers. The number of qubits, choice of
    variational ansatz, cost function, and optimization method are all to be
    developed by you in this function.

    Args:
        circuit (qml.QNode): A circuit that you want to train
        X_train (np.ndarray): An array of floats of size (M, n) to be used as training data.
        Y_train (np.ndarray): An array of size (M,) which are the categorical labels
            associated to the training data. The categories are labeled by -1, 0, and 1.
        X_test (np.ndarray): An array of floats of (B, n) to serve as testing data.
        kwargs: hyperparameters for the training (steps, batch_size, learning_rate)

    Returns:
        (p,i,e,w): The number of parameters, the inference time (time to evaluate the accuracy), error rate (accuracy on the test set)
    &#34;&#34;&#34;

    # Use this array to make a prediction for the labels of the data in X_test
    predictions = []

    # QHACK #

    from autograd.numpy import exp,tanh

    def hinge_loss(labels, predictions,type=&#39;L2&#39;):
        loss = 0
        for l, p in zip(labels, predictions):
            if type==&#39;L1&#39;:
                loss = loss + np.abs(l - p) # L1 loss
            elif type==&#39;L2&#39;:
                loss = loss + (l - p) ** 2 # L2 loss
        loss = loss/len(labels)
        return loss

    def accuracy(labels, predictions):

        loss = 0
        tol = 0.05
        #tol = 0.1
        for l, p in zip(labels, predictions):
            if abs(l - p) &lt; tol:
                loss = loss + 1
        loss = loss / len(labels)

        return loss

    def cost_fcn(params,circuit=None,ang_array=[], actual=[]):
        &#39;&#39;&#39;
        use MAE to start
        &#39;&#39;&#39;
        labels = {2:-1,1:1,0:0}
        n = len(ang_array[0])
        w = params[-n:]
        theta = params[:-n]
        predictions = [2.*(1.0/(1.0+exp(np.dot(-w,circuit(theta, angles=x)))))- 1. for x in ang_array]
        return hinge_loss(actual, predictions)

    var = np.hstack((np.zeros(n_params),5*np.random.random(X_train.shape[1])-2.5))
    steps = kwargs[&#39;s&#39;]
    batch_size = kwargs[&#39;batch_size&#39;]
    num_train = len(Y_train)
    validation_size = int(num_train//2)
    opt = optim(**optimoptions)
    start = time.time()
    for _ in range(steps):
        batch_index = np.random.randint(0, num_train, (batch_size,))
        X_train_batch = X_train[batch_index]
        Y_train_batch = Y_train[batch_index]
        var,cost = opt.step_and_cost(lambda v: cost_fcn(v, circuit,X_train_batch, Y_train_batch), var)
    end = time.time()
    cost_time = (end-start)

    w = var[-X_train.shape[1]:]
    theta = var[:-X_train.shape[1]]

    if rate_type ==&#39;accuracy&#39;:
        start = time.time() # add in timeit function from Wbranch
        predictions=[int(np.round(2.*(1.0/(1.0+exp(np.dot(-w,circuit(theta, angles=x)))))- 1.,0)) for x in X_test]
        end = time.time()
        if inference==&#39;wall_clock&#39;:
            inftime = (end-start)/len(X_test)
        err_rate = 1.0 - accuracy(predictions,Y_test)
    elif rate_type==&#39;batch_cost&#39;:
        err_rate = cost
        inftime = cost_time
    # QHACK #
    if inference==&#39;cnots&#39;:
        inftime=n_cnots
        
    W_ = np.abs((100.-len(var))/(100.))*np.abs((100.-inftime)/(100.))*(1./err_rate)
    return len(var),inftime,err_rate,W_</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="qose" href="index.html">qose</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="qose.training_test.classify_data" href="#qose.training_test.classify_data">classify_data</a></code></li>
<li><code><a title="qose.training_test.train_circuit" href="#qose.training_test.train_circuit">train_circuit</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>