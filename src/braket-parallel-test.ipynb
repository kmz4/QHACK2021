{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to run a basic test to check if running QOSE on AWS is quicker. first we try this without parallelizing gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subarchitecture_tree_search import run_tree_architecture_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create a unique name for your experiment\n",
    "    EXPERIMENT_NAME = 'LocalvsRemoteTree'\n",
    "\n",
    "    # Create a directory to store the data\n",
    "    if not os.path.exists('data'):\n",
    "        os.mkdir('data/')\n",
    "\n",
    "    data_path = f'data/{EXPERIMENT_NAME}'\n",
    "    if not os.path.exists(data_path):\n",
    "        os.mkdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    config = {'nqubits': 5,\n",
    "              'min_tree_depth': 2,\n",
    "              'max_tree_depth': 20,\n",
    "              'prune_rate': 0.3,\n",
    "              'prune_step': 3,\n",
    "              'plot_trees': False,\n",
    "              'data_set': 'moons',\n",
    "              'nsteps': 20,\n",
    "              'opt': qml.AdamOptimizer,\n",
    "              'batch_size': 25,\n",
    "              'n_samples': 1500,\n",
    "              'learning_rate': 0.01,\n",
    "              'save_frequency': 1,\n",
    "              'save_path': data_path\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    with open(data_path + '/config.pickle', 'wb') as f:\n",
    "        pickle.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth = 1\n",
      "Depth = 2\n",
      "Prune Tree\n",
      "Grow Pruned Tree\n",
      "Depth = 3\n",
      "Grow Tree\n",
      "Depth = 4\n",
      "Grow Tree\n",
      "Depth = 5\n",
      "Prune Tree\n",
      "Grow Pruned Tree\n",
      "Depth = 6\n",
      "Grow Tree\n",
      "Depth = 7\n",
      "Grow Tree\n",
      "Depth = 8\n",
      "Prune Tree\n",
      "Grow Pruned Tree\n",
      "Depth = 9\n",
      "Grow Tree\n",
      "Depth = 10\n",
      "Grow Tree\n",
      "Depth = 11\n",
      "Prune Tree\n",
      "Grow Pruned Tree\n",
      "Depth = 12\n",
      "Grow Tree\n",
      "Depth = 13\n",
      "Grow Tree\n",
      "Depth = 14\n",
      "Prune Tree\n",
      "Grow Pruned Tree\n",
      "Depth = 15\n",
      "Grow Tree\n",
      "Depth = 16\n",
      "Grow Tree\n",
      "Depth = 17\n",
      "Prune Tree\n",
      "Grow Pruned Tree\n",
      "Depth = 18\n",
      "Grow Tree\n",
      "Depth = 19\n",
      "Grow Tree\n"
     ]
    }
   ],
   "source": [
    "t_0_local = time.time()\n",
    "run_tree_architecture_search(config, \"local\")\n",
    "t_1_local = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t_0_remote = time.time()\n",
    "run_tree_architecture_search(config, \"remote\")\n",
    "t_1_remote = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Execution time on remote device (seconds):\", t_1_remote - t_0_remote)\n",
    "print(\"Execution time on local device (seconds):\", t_1_local - t_0_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + '/tree_depth_2.pickle', \"rb\") as f:\n",
    "        results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    restore_depth = 3\n",
    "    with open(data_path + f'/tree_depth_{restore_depth}.pickle', 'rb') as f:\n",
    "        G = pickle.load(f)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.get_node_attributes(G, 'W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_qnode_remote = qml.grad(qnode_remote)\n",
    "\n",
    "t_0_remote_grad = time.time()\n",
    "d_qnode_remote(params)\n",
    "t_1_remote_grad = time.time()\n",
    "\n",
    "print(\"Gradient calculation time on remote device (seconds):\", t_1_remote_grad - t_0_remote_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_qnode_local = qml.grad(qnode_local)\n",
    "\n",
    "t_0_local_grad = time.time()\n",
    "d_qnode_local(params)\n",
    "t_1_local_grad = time.time()\n",
    "\n",
    "print(\"Gradient calculation time on local device (seconds):\", t_1_local_grad - t_0_local_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWSAccessKeyId=AKIAI32BQOUGFFNZLB5A\n",
    "AWSSecretKey=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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. rst-class:: sphx-glr-script-out\n",
    "\n",
    " Out:\n",
    "\n",
    " .. code-block:: none\n",
    "\n",
    "     Gradient calculation time on local device (seconds): 941.8518133479993\n",
    "\n",
    "Wow, the local device needs around 15 minutes or more! Compare this to less than a minute spent\n",
    "calculating the gradient on SV1. This provides a powerful lesson in parallelization.\n",
    "\n",
    "What if we had run on SV1 with ``parallel=False``? It would have taken around 3 minutesâ€”still\n",
    "faster than a local device, but much slower than running SV1 in parallel.\n",
    "\n",
    "Scaling up QAOA for larger graphs\n",
    "---------------------------------\n",
    "\n",
    "The quantum approximate optimization algorithm (QAOA) is a candidate algorithm for near-term\n",
    "quantum hardware that can find approximate solutions to combinatorial optimization\n",
    "problems such as graph-based problems. We have seen in the main\n",
    ":doc:`QAOA tutorial<tutorial_qaoa_intro>` how QAOA successfully solves the minimum vertex\n",
    "cover problem on a four-node graph.\n",
    "\n",
    "Here, let's be ambitious and try to solve the maximum cut problem on a twenty-node graph! In\n",
    "maximum cut, the objective is to partition the graph's nodes into two groups so that the number\n",
    "of edges crossed or 'cut' by the partition is maximized (see the diagram below). This problem is\n",
    "NP-hard, so we expect it to be tough as we increase the number of graph nodes.\n",
    "\n",
    ".. figure:: ../_static/max-cut.png\n",
    "    :align: center\n",
    "    :scale: 100%\n",
    "    :alt: The maximum cut problem\n",
    "    :target: javascript:void(0);\n",
    "\n",
    "Let's first set the graph:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "nodes = n_wires = 20\n",
    "edges = 60\n",
    "seed = 1967\n",
    "\n",
    "g = nx.gnm_random_graph(nodes, edges, seed=seed)\n",
    "positions = nx.spring_layout(g, seed=seed)\n",
    "\n",
    "nx.draw(g, with_labels=True, pos=positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. figure:: ../_static/20_node_graph.png\n",
    "    :align: center\n",
    "    :scale: 100%\n",
    "    :target: javascript:void(0);\n",
    "\n",
    "We will use the remote SV1 device to help us optimize our QAOA circuit as quickly as possible.\n",
    "First, the device is loaded again for 20 qubits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\n",
    "    \"braket.aws.qubit\",\n",
    "    device_arn=device_arn,\n",
    "    wires=n_wires,\n",
    "    s3_destination_folder=s3_folder,\n",
    "    parallel=True,\n",
    "    max_parallel=20,\n",
    "    poll_timeout_seconds=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the specification of ``max_parallel=20``. This means that up to ``20`` circuits will be\n",
    "executed in parallel on SV1 (the default value is ``10``).\n",
    "\n",
    "<div class=\"alert alert-danger\"><h4>Warning</h4><p>Increasing the maximum number of parallel executions can result in a greater rate of\n",
    "    spending on simulation fees on Amazon Braket. The value must also be set bearing in mind your\n",
    "    service\n",
    "    `quota <https://docs.aws.amazon.com/braket/latest/developerguide/braket-quotas.html>`__.</p></div>\n",
    "\n",
    "The QAOA problem can then be set up following the standard pattern, as discussed in detail in\n",
    "the :doc:`QAOA tutorial<tutorial_qaoa_intro>`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_h, mixer_h = qml.qaoa.maxcut(g)\n",
    "n_layers = 2\n",
    "\n",
    "\n",
    "def qaoa_layer(gamma, alpha):\n",
    "    qml.qaoa.cost_layer(gamma, cost_h)\n",
    "    qml.qaoa.mixer_layer(alpha, mixer_h)\n",
    "\n",
    "\n",
    "def circuit(params, **kwargs):\n",
    "    for i in range(n_wires):  # Prepare an equal superposition over all qubits\n",
    "        qml.Hadamard(wires=i)\n",
    "\n",
    "    qml.layer(qaoa_layer, n_layers, params[0], params[1])\n",
    "\n",
    "\n",
    "cost_function = qml.ExpvalCost(circuit, cost_h, dev, optimize=True)\n",
    "optimizer = qml.AdagradOptimizer(stepsize=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now set up to train the circuit! Note, if you are training this circuit yourself, you may\n",
    "want to increase the number of iterations in the optimization loop and also investigate changing\n",
    "the number of QAOA layers.\n",
    "\n",
    "<div class=\"alert alert-danger\"><h4>Warning</h4><p>The following lines are computationally intensive. Remember that running it will result in\n",
    "    simulation fees charged to your AWS account. We recommend monitoring your usage on the AWS\n",
    "    dashboard.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "np.random.seed(1967)\n",
    "params = 0.01 * np.random.uniform(size=[2, n_layers])\n",
    "iterations = 10\n",
    "\n",
    "for i in range(iterations):\n",
    "    t0 = time.time()\n",
    "\n",
    "    params, cost_before = optimizer.step_and_cost(cost_function, params)\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    if i == 0:\n",
    "        print(\"Initial cost:\", cost_before)\n",
    "    else:\n",
    "        print(f\"Cost at step {i}:\", cost_before)\n",
    "\n",
    "    print(f\"Completed iteration {i + 1}\")\n",
    "    print(f\"Time to complete iteration: {t1 - t0} seconds\")\n",
    "\n",
    "print(f\"Cost at step {iterations}:\", cost_function(params))\n",
    "\n",
    "np.save(\"params.npy\", params)\n",
    "print(\"Parameters saved to params.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. rst-class:: sphx-glr-script-out\n",
    "\n",
    " Out:\n",
    "\n",
    " .. code-block:: none\n",
    "\n",
    "   Initial cost: -29.98570234095951\n",
    "   Completed iteration 1\n",
    "   Time to complete iteration: 93.96246099472046 seconds\n",
    "   Cost at step 1: -27.154071768632154\n",
    "   Completed iteration 2\n",
    "   Time to complete iteration: 84.80994844436646 seconds\n",
    "   Cost at step 2: -29.98726230006233\n",
    "   Completed iteration 3\n",
    "   Time to complete iteration: 83.13504934310913 seconds\n",
    "   Cost at step 3: -29.999163153600062\n",
    "   Completed iteration 4\n",
    "   Time to complete iteration: 85.61391234397888 seconds\n",
    "   Cost at step 4: -30.002158646044307\n",
    "   Completed iteration 5\n",
    "   Time to complete iteration: 86.70688223838806 seconds\n",
    "   Cost at step 5: -30.012058444011906\n",
    "   Completed iteration 6\n",
    "   Time to complete iteration: 83.26341080665588 seconds\n",
    "   Cost at step 6: -30.063709712612443\n",
    "   Completed iteration 7\n",
    "   Time to complete iteration: 85.25566911697388 seconds\n",
    "   Cost at step 7: -30.32522304705352\n",
    "   Completed iteration 8\n",
    "   Time to complete iteration: 83.55433392524719 seconds\n",
    "   Cost at step 8: -31.411030331978186\n",
    "   Completed iteration 9\n",
    "   Time to complete iteration: 84.08745908737183 seconds\n",
    "   Cost at step 9: -33.87153965616938\n",
    "   Completed iteration 10\n",
    "   Time to complete iteration: 87.4032838344574 seconds\n",
    "   Cost at step 10: -36.05424874438809\n",
    "   Parameters saved to params.npy\n",
    "\n",
    "This example shows us that a 20-qubit QAOA problem can be trained within around 1-2 minutes per\n",
    "iteration by using parallel executions on the Amazon Braket SV1 device to speed up gradient\n",
    "calculations. If this problem were run on ``default.qubit`` without parallelization, we would\n",
    "expect for training to take much longer.\n",
    "\n",
    "The results of this optimization can be investigated by saving the parameters\n",
    ":download:`here </demonstrations/braket/params.npy>` to your working directory. See if you can\n",
    "analyze the performance of this optimized circuit following a similar strategy to the\n",
    ":doc:`QAOA tutorial<tutorial_qaoa_intro>`. Did we find a large graph cut?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
